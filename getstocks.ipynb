{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import twstock\n",
    "import requests as re\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up engine to transfer data from Python to Postgres\n",
    "engine = sqlalchemy.create_engine('postgresql://postgres:password@localhost:5432/stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the headers for web-scraping\n",
    "headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "        'referrer': 'https://google.com',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Pragma': 'no-cache',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Company Info\n",
    "compinfo = BeautifulSoup(re.get('https://stock.wespai.com/lists', headers=headers).content, 'html.parser').find_all('tr')\n",
    "\n",
    "d = {'stock_no':[], 'stock_name':[], 'stock_cat':[]}\n",
    "for comp in compinfo:\n",
    "    try:\n",
    "        comp = comp.find_all('td')\n",
    "        d['stock_no'].append(comp[0].text)\n",
    "        d['stock_name'].append(comp[1].text)\n",
    "        d['stock_cat'].append(comp[2].text)\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.to_sql('compinfo',con=engine,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get stock info for market companies\n",
    "def getstock_dailyinfo(nos):\n",
    "    for no in nos:\n",
    "        print(no)\n",
    "        if len(no) == 4:\n",
    "            try:\n",
    "                for month in ['01','02','03','04','05','06','07','08','09','10','11','12']:\n",
    "                    data = BeautifulSoup(re.get('https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=csv&date=2020'+month+'01'+'&stockNo='+str(no), headers=headers).content, 'html.parser').text.split('\\n')[2:-6]\n",
    "                    for dayinfo in data:\n",
    "                        cleaned = [s.replace('\"','').replace(',','').replace('\\r','').replace('+','') for s in dayinfo.split('\",\"')]\n",
    "                        cleaned.insert(0,str(no))\n",
    "                        engine.execute(\"INSERT INTO day VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) on conflict on constraint uniq do nothing\", (tuple(cleaned)))\n",
    "                    time.sleep(5)\n",
    "\n",
    "                data = BeautifulSoup(re.get('https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=csv&date=20210101'+'&stockNo='+str(no), headers=headers).content, 'html.parser').text.split('\\n')[2:-6]\n",
    "                for dayinfo in data:\n",
    "                    cleaned = [s.replace('\"','').replace(',','').replace('\\r','').replace('+','') for s in dayinfo.split('\",\"')]\n",
    "                    cleaned.insert(0,str(no))\n",
    "                    engine.execute(\"INSERT INTO day VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) on conflict on constraint uniq do nothing\", (tuple(cleaned)))\n",
    "                time.sleep(5)\n",
    "\n",
    "                data = BeautifulSoup(re.get('https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=csv&date=20210201'+'&stockNo='+str(no), headers=headers).content, 'html.parser').text.split('\\n')[2:-6]\n",
    "                for dayinfo in data:\n",
    "                    cleaned = [s.replace('\"','').replace(',','').replace('\\r','').replace('+','') for s in dayinfo.split('\",\"')]\n",
    "                    cleaned.insert(0,str(no))\n",
    "                    engine.execute(\"INSERT INTO day VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) on conflict on constraint uniq do nothing\", (tuple(cleaned)))    \n",
    "                time.sleep(5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(no, e)\n",
    "                time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Institutional Investors data\n",
    "today = str(datetime.date.today()).replace('-','')\n",
    "data = BeautifulSoup(re.get('https://www.twse.com.tw/fund/T86?response=json&date='+today+'&selectType=ALL', headers=headers).content, 'html.parser').text.split('\\n')\n",
    "data = eval(data[0])\n",
    "if data['stat'] == 'OK':\n",
    "    inv = pd.DataFrame(data['data'], columns=[c.replace('(','').replace(')','') for c in data['fields']])\n",
    "    inv['date'] = pd.Series([today]*inv.shape[0])\n",
    "    inv.to_sql('lawman', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather daily stock data for market companies\n",
    "ids = [s for s in list(twstock.twse.keys()) if len(s) == 4]\n",
    "getstock_dailyinfo(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A faster approach to get daily stock info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock data for the past 120 days\n",
    "PAST = 120\n",
    "for dayspast in range (PAST):\n",
    "    try:\n",
    "        d = str(datetime.date.today()-datetime.timedelta(days=dayspast)).replace('-','')\n",
    "        stocksinfo = BeautifulSoup(re.get('https://www.twse.com.tw/exchangeReport/MI_INDEX?response=html&date='+d+'&type=ALLBUT0999', headers=headers).content, 'html.parser').find_all('table')[-1].find_all('tr')\n",
    "        d = datetime.date.today()-datetime.timedelta(days=dayspast)\n",
    "        date = (str(d.year - 1911) + '/' + str(d)[5:]).replace('-','/')\n",
    "        for stockindex in range (len(stocksinfo)):\n",
    "            if stockindex >= 3:\n",
    "                s = stocksinfo[stockindex].find_all('td')\n",
    "\n",
    "                try:\n",
    "                    engine.execute(\"INSERT INTO day VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) on conflict on constraint dayuniq1 do nothing\", (s[0].text, date, s[2].text, s[4].text, s[5].text, s[6].text, s[7].text, s[8].text, eval(s[9].text+s[10].text), s[3].text))\n",
    "                except SyntaxError:\n",
    "                    engine.execute(\"INSERT INTO day VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s) on conflict on constraint dayuniq1 do nothing\", (s[0].text, date, s[2].text, s[4].text, s[5].text, s[6].text, s[7].text, s[8].text, 0, s[3].text))\n",
    "        time.sleep(5)\n",
    "    except IndexError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
